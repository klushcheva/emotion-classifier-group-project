# МОВС, годовой проект 2023

## Участники: Павел Егоров, Мария Аугуст, Ксения Лущева

## Проект: Изучение социального настроения граждан c помощью машинного обучения

### Оглавление
- [Ссылки для скачивания](#ссылки-для-скачивания)
- [Описание проекта](#описание-проекта)
  - [Актуальность решаемой проблемы](#актуальность-решаемой-проблемы)
  - [Описание датасета](#описание-датасета)
- [Шаги выполненные на текущий момент](#шаги-выполненные-на-текущий-момент)
  - [Шаг 0. Ручная разметка датасета](#шаг-0-ручная-разметка-датасета)
  - [Шаг 1. Bag of Words](#шаг-1-bag-of-words)
  - [Шаг 2. TfIdfVectorizer](#шаг-2-tfidfvectorizer)
  - [Шаг 3. Включение дополнительных признаков в TfIdfVectorizer](#шаг-3-включение-дополнительных-признаков-в-tfidfvectorizer)
  - [Шаг 4. Word2Vec](#шаг-4-word2vec)
  - [Шаг 5. BERT](#шаг-5-bert)
  - [Шаг 6. FastAPI](#шаг-6-fastapi)
- [Алгоритм запуска модели для тестирования](#алгоритм-запуска-модели-для-тестирования)

### Ссылки для скачивания
Ввиду того, что модель и зависимости имеют размер, превышающий допустимый для скачивания в GitHub, часть важный файлов вынесена в ссылки:

- [Скачать весь проект](https://disk.yandex.ru/d/PnmU1PZmgIqAcg)
- [Зависимости проекта](https://disk.yandex.ru/d/pPLhMK-pWAvmAg)
- [Модель (.bin)](https://disk.yandex.ru/d/lCz-SImQZc19GA)


### Описание проекта
#### Актуальность решаемой пробелемы
Развитие социальных наук значительно отстает на фоне стремительного прогресса в области Data Science. Этот прогресс выражается в резком расширении доступности информации, которая значительно превосходит традиционные базы данных социальных наук, а также в появлении новых инструментов анализа (в первую очередь, инструментов машинного обучения).

Это отставание создает проблемы не только для теории, но и для практики, поскольку растущая изменчивость и турбулентность социального мира (например, пандемия COVID-19 или институциональные кризисы 2022-2023 годов) требуют повышения эффективности и точности анализа социальных процессов для политики.

Важно учитывать общие социальные настроения и выделять наиболее волнующие общество темы. Этот проект направлен на решение этих задач с использованием методов машинного обучения и анализа текстов на данных из социальной сети ВКонтакте.

### Описание датасета

Alexandrova, Julia; Savina, Ekaterina; Goiko, Vyacheslav; Petrov, Evgeny (2023), “Dataset containing posts and comments from university publics on the social media VKontakte”, Mendeley Data, V1, doi: 10.17632/fcyfn32mv6.1
- [Источник датасета на Mendeley](https://data.mendeley.com/datasets/fcyfn32mv6/1)

Датасет представляет собой коллекцию контента, опубликованного в группах российских университетов в социальной сети ВКонтакте. Датасет включает посты и комментарии от 9 187 публичных страниц университетов, собранные в период с сентября 2021 года по июнь 2022 года (один учебный год). Общее количество объектов в датасете составляет 2 700 000 записей.

Столбцы датасета:

```inner_id``` — внутренний идентификатор записи, который облегчает навигацию и управление данными.

```univ_name``` — название университета, к которому относится пост или комментарий.

```name``` — название группы или страницы, на которой опубликован контент.

```group_id``` — уникальный идентификатор группы ВКонтакте.

```screen_name``` — сокращенное имя группы (screen name), используемое в URL.

```id``` — идентификатор поста или комментария в ВКонтакте.

```date``` — дата и время публикации поста или комментария, важная для временного анализа.

```comments``` — количество комментариев к посту, что помогает оценить уровень вовлеченности аудитории.

```likes``` — количество отметок «Нравится», которое указывает на популярность публикации.

```reposts``` — количество репостов, что позволяет оценить степень распространения поста.

```views``` — количество просмотров публикации, полезное для анализа охвата.

```comment``` — текст комментария к посту (если имеется).

```text_type``` — тип текста, указывающий, является ли он постом или комментарием.

```post``` — содержание поста, отражающее основной контент, который был опубликован в группе.

### Шаги выполненные на текущий момент:

#### Шаг 0. Ручная разметка датасета
В датасет добавлен столбец ```tonality```

```tonality``` — эмоциональная тональность текста (позитивная, негативная, нейтральная).

Ручная размета позволила, в последствии, обучить наиболее эффективную модель из всех. Все в ручную размечено 20000 постов.

#### Шаг 1. Bag of Words 

Подход, использующий метод Bag of Words (BoW) в сочетании с CountVectorizer и Logistic Regression для обучения языковых моделей, является прочным фундаментом в обработке естественного языка (NLP), поэтому мы решили начать с него. В результате использования (BoW) для столбца sentiment получили:

- Высокую точность при использовании 1-граммовой модели.
- Достижение точности 0,94 с помощью 1-граммовой модели впечатляет и указывает на то, что модель очень эффективно классифицирует настроения как положительные или отрицательные на основе отдельных слов. Это говорит о том, что для набора данных наличие или отсутствие определенных ключевых слов является сильным предиктором настроения.
- Мы получили снижение точности при использовании 3-граммовой модели.
- Снижение точности до 0,85 при использовании 3-граммовой модели скорее всего говорит о том, что включение контекста окружающих слов (до трех слов вместе) не только не улучшает, но даже может несколько ухудшить работу модели. 
- Хотя подход Bag of Words прост и эффективен для многих задач, он не учитывает порядок слов и семантические отношения между словами. Поэтому на следующих этапах мы постарались учесть более сложные модели.
#### Шаг 2. TfIdfVectorizer 

TfIdfVectorizer и расширение значений целевых переменных демонстрирует развитие и масштабирование проекта

- Использование TfIdfVectorizer с LogisticRegression сохраняет высокую точность бинарной классификации (положительная/отрицательная) как с 1-граммовой, так и с 3-граммовой моделями. 
- Небольшое увеличение точности 3-граммовой модели с использованием TfIdfVectorizer (с 0,85 до 0,86) по сравнению с подходом BoW позволяет предположить, что взвешивание TfIdf, которое подчеркивает важность менее частотных слов, может быть более эффективным для улавливания нюансов контекста в больших n-граммах.
- Получили первую проблему с многоклассовой классификацией. Расширение категории до "нейтральный" и обучение ряда классификаторов на векторах (1,2)-грамм показало заметное падение точности во всех моделях. 
- Это указывает на возросшую сложность различения трех классов настроений, особенно с добавлением категории "нейтральный", которая может пересекаться с характеристиками как "позитивных", так и "негативных" настроений.
- Также это может указывать на недостаточно хорошую разметку данных, в связи с чем, одной из потенциально решаемых задач в нашей работе - уточнение сентиментов.
- Низкие показатели F1 для позитивных/негативных настроений. Показатели f1 для положительных и отрицательных категорий ниже 0,3 свидетельствуют о значительных проблемах в достижении сбалансированной классификации с помощью текущих моделей, особенно в различении положительных и отрицательных настроений в трехклассовой системе. Это говорит о том, что модели предвзяты к "нейтральной" категории или пытаются найти отличительные признаки для "позитивного" и "негативного".
- Последующий анализ доказывает это.
![Heatmap for data with positive and negative sentiment](/assets/target_is_2.jpeg "Heatmap for data with positive and negative sentiment")
![Heatmap for data with positive, negative and neutral sentiment](/assets/target_is_3.jpeg "Heatmap for data with positive, negative and neutral sentiment")

#### Шаг 3. Включение дополнительных признаков в TfIdfVectorizer 

На следующем шаге мы постарались включить дополнительные параметры:
- Добавление новых признаков, таких как emotion, toxicity, is_congratulation и spam, наряду с существующими текстовыми данными представляет собой стратегический подход к улучшению понимания моделью глубинного контекста и нюансов текстовых данных. 

- Включая такие признаки, как эмоциональность, токсичность, is_congratulation и спам, мы позволяем модели улавливать более широкий спектр текстовых нюансов, что может значительно улучшить ее способность понимать и точно классифицировать текст. Эти особенности могут дать ценные сигналы, которые не улавливаются только текстом.

- Использование OHE для этих дополнительных признаков - подходящий выбор для категориальных данных, поскольку оно позволяет модели рассматривать каждую категорию как отдельную сущность, не подразумевая никакого порядка. Это может помочь в точном отражении влияния каждого признака на целевую переменную.

- Продолжение использования TfIdf для кодирования текста с помощью 1-грамм гарантирует, что модель учитывает важность каждого слова в корпусе, уменьшая при этом влияние часто встречающихся слов. Это позволяет сбалансировать набор признаков между вновь добавленными категориальными признаками и текстовыми данными.

- Мы применили TruncatedSVD для сжатия матрицы признаков до 100 признаков. Это поможет решить проблемы, связанные с высокой размерностью, такие как проклятие размерности и чрезмерная подгонка, что сделает вашу модель более обобщенной. Кроме того, SVD может выявить скрытые связи между признаками, что потенциально повышает производительность модели.

#### Шаг 4. Word2Vec

Мы предприняли переход к использованию nltk для удаления стоп-слов и модели Word2Vec для векторизации текста. Ниже подробный обзор этих шагов:

- Использование nltk для удаления стоп-слов. Удаление стоп-слов имеет решающее значение для уменьшения шума в текстовых данных. Это помогает сфокусироваться на словах, которые предлагают более значимые идеи или чувства.
  
- nltk, ведущая библиотека Python для обработки естественного языка, предоставляет список стоп-слов. Мы отфильтровали свои текстовые данные по этому списку, удалив эти слова перед дальнейшей обработкой.

- Использование Word2Vec для векторизации текста. Word2Vec - двухслойная нейронная сеть, которая обрабатывает текст, "обучаясь" векторным представлениям слов. Она учитывает контекстуальные нюансы и семантические связи между словами, в отличие от методов BoW и TfIdf, которые рассматривают слова как независимые сущности. Используя Word2Vec, мы преобразуем текст в векторы, которые представляют слова в непрерывном векторном пространстве. Это означает, что слова с похожими значениями расположены близко друг к другу в этом пространстве, что может значительно повысить способность модели понимать нюансы текста.
  
- Этот подход особенно эффективен для улавливания контекста слов, понимания синонимов и для улавливания определенного настроения. Мы рассчитываем, что  в нашем случае это приведет к созданию более эффективной модели, особенно для задач, требующих глубокого понимания семантики текста, таких как анализ настроения, классификация текстов и рекомендательные системы.

#### Шаг 5. BERT

На данном шаге обучена модель для анализа тональности текста на основе архитектуры BERT. 
Использована предобученная модель DeepPavlov/rubert-base-cased, которая дообучалась на размеченном датасете, содержащем посты и их тональности (позитивная, нейтральная, негативная). 

Датасет был загружен и разделён на обучающую, валидационную и тестовую выборки. Для каждой выборки была выполнена токенизация текста с использованием предобученного токенизатора BERT. Была определена кастомная модель BertSentimentAnalyzer, которая включала BERT для извлечения признаков и линейный слой для классификации тональности. Для обучения модели использовался класс Trainer с настроенными параметрами, такими как количество эпох, размер батча и шаги логирования. После обучения на тестовой выборке были вычислены метрики с помощью classification_report. Конечная модель, её конфигурация и токенизатор были сохранены для дальнейшего использования. Было выполнено предсказание тональности для произвольного текста с использованием обученной модели.

Код данного шага представлен в файле: learning_model.py

#### Шаг 6. FastAPI

На данном этапе было создано веб-приложение на базе FastAPI для анализа тональности текста с использованием предобученной модели BERT. Приложение инициализировалось с помощью библиотеки FastAPI. 
В директорию без кириллицы был загружен токенизатор и веса модели, которые были сохранены ранее. 

Для работы с текстами была реализована кастомная модель BertSentimentAnalyzer, основанная на архитектуре BERT и дообученная для задачи классификации тональности. Модель была загружена и приведена в режим готовности для предсказаний. 

Был создан маршрут /analyze, через который пользователь мог отправлять POST-запросы с текстом для анализа. Текст поступал в модель через токенизацию и предобработку, после чего модель предсказывала тональность (негативная, нейтральная или позитивная). Предсказанная тональность возвращалась в виде JSON-ответа с указанием исходного текста и результата. Код подготовлен для локального запуска, и приложение могло обрабатывать запросы через веб-интерфейс.


### Алгоритм запуска модели для тестирования:

Для Винды:
python -m venv venv
venv\Scripts\activate

Для Линукс или Мака: 
python3 -m venv venv
source venv/bin/activate

Далее:
Установите необходимые библиотеки:
pip install fastapi uvicorn transformers torch

Укажите корректный путь к модели:
model_path = r'C: ЗДЕСЬ директория, куда скачали модель'

Запустите FastAPI:
uvicorn app:app --reload
После этого сервер будет доступен по адресу http://127.0.0.1:8000.

Далее работайте в интерфейсе Swagger UI FastAPI:

- Выберите маршрут /analyze [POST].

- Нажмите кнопку Try it out.

- Введите текст для анализа в формате JSON
  
- Нажмите кнопку Execute для выполнения запроса. Вы увидите результат анализа текста.

Если хотите протестировать через curl:
Тестирование через curl: Можно также отправлять запросы через командную строку с помощью curl:
curl -X 'POST' \
  'http://127.0.0.1:8000/analyze' \
  -H 'Content-Type: application/json' \
  -d '{"text": "Этот день был прекрасным!"}'
